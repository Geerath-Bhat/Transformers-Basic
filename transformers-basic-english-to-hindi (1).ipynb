{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece] sacrebleu -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-07T18:35:18.427087Z","iopub.execute_input":"2023-08-07T18:35:18.427473Z","iopub.status.idle":"2023-08-07T18:35:31.961864Z","shell.execute_reply.started":"2023-08-07T18:35:18.427444Z","shell.execute_reply":"2023-08-07T18:35:31.960576Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:35:45.921125Z","iopub.execute_input":"2023-08-07T18:35:45.921528Z","iopub.status.idle":"2023-08-07T18:35:58.950465Z","shell.execute_reply.started":"2023-08-07T18:35:45.921493Z","shell.execute_reply":"2023-08-07T18:35:58.949626Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:08:17.835152Z","iopub.execute_input":"2023-08-07T19:08:17.835558Z","iopub.status.idle":"2023-08-07T19:08:17.840302Z","shell.execute_reply.started":"2023-08-07T19:08:17.835527Z","shell.execute_reply":"2023-08-07T19:08:17.839213Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:08:19.540179Z","iopub.execute_input":"2023-08-07T19:08:19.540591Z","iopub.status.idle":"2023-08-07T19:08:21.764578Z","shell.execute_reply.started":"2023-08-07T19:08:19.540557Z","shell.execute_reply":"2023-08-07T19:08:21.763680Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9de22c34587430eb1f5b5bca6e06945"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:39:15.509896Z","iopub.execute_input":"2023-08-07T18:39:15.510776Z","iopub.status.idle":"2023-08-07T18:39:15.518160Z","shell.execute_reply.started":"2023-08-07T18:39:15.510734Z","shell.execute_reply":"2023-08-07T18:39:15.517140Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1659083\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets['train'][1]","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:39:36.239857Z","iopub.execute_input":"2023-08-07T18:39:36.240251Z","iopub.status.idle":"2023-08-07T18:39:36.247774Z","shell.execute_reply.started":"2023-08-07T18:39:36.240222Z","shell.execute_reply":"2023-08-07T18:39:36.246491Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'Accerciser Accessibility Explorer',\n  'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'}}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:40:31.713756Z","iopub.execute_input":"2023-08-07T18:40:31.714544Z","iopub.status.idle":"2023-08-07T18:40:36.027216Z","shell.execute_reply.started":"2023-08-07T18:40:31.714504Z","shell.execute_reply":"2023-08-07T18:40:36.024639Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b9b2179b5be4a74ab7f0549d11a8abe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd4a191176841c69b7f27e8340fe873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a414bf256fe441082a904b74ea6740c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb1e249af1d4e21bcebe47811d4fec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be09f1b88fed4646b1fc0adfaacd3013"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer(\"Hello, this is a sentence!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:41:18.779792Z","iopub.execute_input":"2023-08-07T18:41:18.780257Z","iopub.status.idle":"2023-08-07T18:41:18.788794Z","shell.execute_reply.started":"2023-08-07T18:41:18.780226Z","shell.execute_reply":"2023-08-07T18:41:18.787529Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [12110, 2, 90, 23, 19, 8800, 61, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer(\"Hello,I am Geerath\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:41:38.195103Z","iopub.execute_input":"2023-08-07T18:41:38.195496Z","iopub.status.idle":"2023-08-07T18:41:38.203158Z","shell.execute_reply.started":"2023-08-07T18:41:38.195464Z","shell.execute_reply":"2023-08-07T18:41:38.201995Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [12110, 2, 389, 489, 15642, 581, 10947, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer(\"Hello, this is a sentence!, \"\"This is another sentence.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:42:29.720237Z","iopub.execute_input":"2023-08-07T18:42:29.720637Z","iopub.status.idle":"2023-08-07T18:42:29.728188Z","shell.execute_reply.started":"2023-08-07T18:42:29.720608Z","shell.execute_reply":"2023-08-07T18:42:29.726885Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [12110, 2, 90, 23, 19, 8800, 61, 2, 239, 23, 414, 8800, 3, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\nsource_lang = \"en\"\ntarget_lang = \"hi\"","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:43:34.019259Z","iopub.execute_input":"2023-08-07T18:43:34.019685Z","iopub.status.idle":"2023-08-07T18:43:34.024670Z","shell.execute_reply.started":"2023-08-07T18:43:34.019654Z","shell.execute_reply":"2023-08-07T18:43:34.023415Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, max_length = max_input_length, truncation = True)\n    \n    #setup the tokenizer for target\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length = max_target_length, truncation = True)\n        \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:48:20.207375Z","iopub.execute_input":"2023-08-07T18:48:20.207795Z","iopub.status.idle":"2023-08-07T18:48:20.214356Z","shell.execute_reply.started":"2023-08-07T18:48:20.207765Z","shell.execute_reply":"2023-08-07T18:48:20.213312Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"preprocess_function(raw_datasets[\"train\"][:2])","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:48:53.340972Z","iopub.execute_input":"2023-08-07T18:48:53.342145Z","iopub.status.idle":"2023-08-07T18:48:53.352290Z","shell.execute_reply.started":"2023-08-07T18:48:53.342102Z","shell.execute_reply":"2023-08-07T18:48:53.351074Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0], [32643, 28541, 36253, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0], [26618, 16155, 346, 33383, 0]]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T18:50:02.586085Z","iopub.execute_input":"2023-08-07T18:50:02.586492Z","iopub.status.idle":"2023-08-07T18:57:33.735411Z","shell.execute_reply.started":"2023-08-07T18:50:02.586453Z","shell.execute_reply":"2023-08-07T18:57:33.734296Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19254e31c0d0462cb86e4598f5e4745b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1660 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28e587d85f984fcdb6ee136f886e060e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"363b5dded72e4435857c61ad473c0adb"}},"metadata":{}}]},{"cell_type":"code","source":"model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:08:54.433352Z","iopub.execute_input":"2023-08-07T19:08:54.433762Z","iopub.status.idle":"2023-08-07T19:09:15.798811Z","shell.execute_reply.started":"2023-08-07T19:08:54.433729Z","shell.execute_reply":"2023-08-07T19:09:15.797534Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee6e61808e749d7b8d9d18b2c495acd"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"539df1f909b74089af425cc6e1a974e3"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 2e-5\nweight_decay = 0.01\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:36.841196Z","iopub.execute_input":"2023-08-07T19:09:36.841601Z","iopub.status.idle":"2023-08-07T19:09:36.847165Z","shell.execute_reply.started":"2023-08-07T19:09:36.841566Z","shell.execute_reply":"2023-08-07T19:09:36.846073Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model = model, return_tensors = \"tf\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:39.242343Z","iopub.execute_input":"2023-08-07T19:09:39.242759Z","iopub.status.idle":"2023-08-07T19:09:39.248059Z","shell.execute_reply.started":"2023-08-07T19:09:39.242725Z","shell.execute_reply":"2023-08-07T19:09:39.247025Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"generation_data_collator=DataCollatorForSeq2Seq(tokenizer,model=model,return_tensors = \"tf\",pad_to_multiple_of=128)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:42.072429Z","iopub.execute_input":"2023-08-07T19:09:42.072857Z","iopub.status.idle":"2023-08-07T19:09:42.078271Z","shell.execute_reply.started":"2023-08-07T19:09:42.072825Z","shell.execute_reply":"2023-08-07T19:09:42.077034Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"test\"],\n    batch_size = batch_size,\n    shuffle = True,\n    collate_fn = data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:45.286190Z","iopub.execute_input":"2023-08-07T19:09:45.286582Z","iopub.status.idle":"2023-08-07T19:09:45.637034Z","shell.execute_reply.started":"2023-08-07T19:09:45.286551Z","shell.execute_reply":"2023-08-07T19:09:45.635920Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"validation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size = batch_size,\n    shuffle = False,\n    collate_fn = data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:47.067440Z","iopub.execute_input":"2023-08-07T19:09:47.067867Z","iopub.status.idle":"2023-08-07T19:09:47.130127Z","shell.execute_reply.started":"2023-08-07T19:09:47.067829Z","shell.execute_reply":"2023-08-07T19:09:47.129195Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"generation_dataset = model.prepare_tf_dataset(\n    tokenized_datasets[\"validation\"],\n    batch_size = 8,\n    shuffle = False,\n    collate_fn = generation_data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:49.804071Z","iopub.execute_input":"2023-08-07T19:09:49.805085Z","iopub.status.idle":"2023-08-07T19:09:49.863403Z","shell.execute_reply.started":"2023-08-07T19:09:49.805046Z","shell.execute_reply":"2023-08-07T19:09:49.862364Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamWeightDecay(learning_rate = learning_rate,weight_decay_rate = weight_decay)\nmodel.compile(optimizer = optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:51.674275Z","iopub.execute_input":"2023-08-07T19:09:51.674698Z","iopub.status.idle":"2023-08-07T19:09:51.696157Z","shell.execute_reply.started":"2023-08-07T19:09:51.674662Z","shell.execute_reply":"2023-08-07T19:09:51.695017Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"tf_model/\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:53.176271Z","iopub.execute_input":"2023-08-07T19:09:53.176721Z","iopub.status.idle":"2023-08-07T19:09:54.080539Z","shell.execute_reply.started":"2023-08-07T19:09:53.176684Z","shell.execute_reply":"2023-08-07T19:09:54.079635Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:09:58.383037Z","iopub.execute_input":"2023-08-07T19:09:58.384424Z","iopub.status.idle":"2023-08-07T19:10:02.296818Z","shell.execute_reply.started":"2023-08-07T19:09:58.384376Z","shell.execute_reply":"2023-08-07T19:10:02.295686Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nAll model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at tf_model/.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"My name is Geerath, I am a Machine Learning Engineer\"\n\ntokenized = tokenizer([input_text], return_tensors='np')\nout = model.generate(**tokenized, max_length=128)\nprint(out)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:10:05.280850Z","iopub.execute_input":"2023-08-07T19:10:05.281245Z","iopub.status.idle":"2023-08-07T19:10:11.627589Z","shell.execute_reply.started":"2023-08-07T19:10:05.281215Z","shell.execute_reply":"2023-08-07T19:10:11.626446Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[61949   500   179  2297   428     5     2   104    38  6858  4461 11447\n     57   153   254     0]], shape=(1, 16), dtype=int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer.decode(out[0], skip_special_tokens = True))","metadata":{"execution":{"iopub.status.busy":"2023-08-07T19:10:14.193075Z","iopub.execute_input":"2023-08-07T19:10:14.193488Z","iopub.status.idle":"2023-08-07T19:10:14.200883Z","shell.execute_reply.started":"2023-08-07T19:10:14.193446Z","shell.execute_reply":"2023-08-07T19:10:14.200100Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"मेरा नाम गीतर है, मैं एक मशीन सीखने इंजन कर रहा हूँ\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}